---
title: 高斯混合模型深入解析
date: 2017-05-15 19:54:55
tags: Algorithm，Machine Learning
categories: Machine Learning
comments: true
---

# 前言

GMM是一种提出于上世纪60年代、并在其后被广泛研究而日渐完善的一种分类与回归分析模型，以其模型简单、分类能力强等优势而被广泛地应用于各类问题中。本文就高斯混合模型（GMM,Gaussian Mixture Model）参数如何确立这个问题，详细讲解期望最大化（EM,Expectation Maximization）算法的实施过程。



<!-- more -->



# 历史

> “这要从1989年说起，我那时正在研究神经网络和核方法的性能对比，直到我的丈夫决定使用Vladimir的算法，SVM就诞生了。”  -by Isabelle Guyon

1. 1963年，[Vladimir Vapnik](https://en.wikipedia.org/wiki/Vladimir_Vapnik)在解决模式识别问题时提出了支持向量方法；
2. 1971年，Kimeldorf构造基于支持向量构建核空间的方法；
3. Vapnik等人正式提出统计学习理论。

早在20世纪60年代，Vapnik就已奠定了统计学习的基本理论基础，如经验风险最小化原则下统计学习一致性的条件（收敛性、收敛的可控性、收敛与概率测度定义的无关性，号称机器学习理论的“三个里程碑”）、关于统计学习方法推广性的界的理论，以及在此基础上建立的小样本归纳推理原则等。直到20世纪90年代中后期，能够实现统计学习理论和原则的实用性算法——SVM方法才逐渐被完整地提出，并且在模式识别等人工智能领域得到成功应用，受到广泛地关注。

# 起式


SVM，中文名为支持向量机或支持向量网络，简单来说，它的<font color="FF0000">基本形式</font>是一种二类<u>线性</u><font color="FF0000">监督式</font>**分类或回归**学习模型。通过在样本空间中寻找符合某种最优条件的超平面，将带有类别标签的训练数据进行分类，从而得到分类准则，运用于测试样本集，判断测试样本的所属类别。





